/**
 * LANDMARK-BASED WARP ALIGNMENT
 * 
 * ========================================================================
 * PROBLEM:
 * 
 * Face pixels are composited WITHOUT geometric alignment to the generated
 * face geometry. This causes:
 * - Nose size appears different
 * - Eye spacing is wrong
 * - Mouth width is distorted
 * - Face appears "zoomed" or stretched
 * 
 * ROOT CAUSE:
 * Simple bounding box scaling doesn't preserve facial proportions.
 * The generated face has different geometry than the original.
 * 
 * SOLUTION:
 * Use landmark-based similarity transform to warp original face pixels
 * to match the generated face geometry BEFORE compositing.
 * ========================================================================
 */

import 'server-only'
import sharp from 'sharp'

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface Point {
    x: number
    y: number
}

export interface FaceLandmarks {
    leftEyeCenter: Point
    rightEyeCenter: Point
    noseTip: Point
    leftMouthCorner: Point
    rightMouthCorner: Point
}

export interface SimilarityTransform {
    scale: number
    rotation: number    // radians
    translateX: number
    translateY: number
}

export interface BoundingBox {
    x: number
    y: number
    width: number
    height: number
}

export interface WarpAlignmentResult {
    success: boolean
    warpedFaceBuffer: Buffer
    transform: SimilarityTransform
    error?: string
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// LANDMARK ESTIMATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Estimate facial landmarks from a face bounding box.
 * 
 * In production, use a proper face landmark detector (MediaPipe, dlib, etc.)
 * This is a geometric estimation based on standard facial proportions.
 */
export function estimateLandmarksFromBox(faceBox: BoundingBox): FaceLandmarks {
    const { x, y, width, height } = faceBox

    // Standard facial proportions (approximate)
    // Eyes at ~35% from top, ~25% and ~75% from sides
    // Nose tip at ~65% from top, center
    // Mouth at ~80% from top

    return {
        leftEyeCenter: {
            x: x + width * 0.30,
            y: y + height * 0.35
        },
        rightEyeCenter: {
            x: x + width * 0.70,
            y: y + height * 0.35
        },
        noseTip: {
            x: x + width * 0.50,
            y: y + height * 0.60
        },
        leftMouthCorner: {
            x: x + width * 0.35,
            y: y + height * 0.78
        },
        rightMouthCorner: {
            x: x + width * 0.65,
            y: y + height * 0.78
        }
    }
}

/**
 * Calculate the center point between two eyes.
 */
export function getEyeCenter(landmarks: FaceLandmarks): Point {
    return {
        x: (landmarks.leftEyeCenter.x + landmarks.rightEyeCenter.x) / 2,
        y: (landmarks.leftEyeCenter.y + landmarks.rightEyeCenter.y) / 2
    }
}

/**
 * Calculate the inter-ocular distance (distance between eyes).
 */
export function getInterocularDistance(landmarks: FaceLandmarks): number {
    const dx = landmarks.rightEyeCenter.x - landmarks.leftEyeCenter.x
    const dy = landmarks.rightEyeCenter.y - landmarks.leftEyeCenter.y
    return Math.sqrt(dx * dx + dy * dy)
}

/**
 * Calculate face rotation angle from eye positions.
 */
export function getFaceRotation(landmarks: FaceLandmarks): number {
    const dx = landmarks.rightEyeCenter.x - landmarks.leftEyeCenter.x
    const dy = landmarks.rightEyeCenter.y - landmarks.leftEyeCenter.y
    return Math.atan2(dy, dx)
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SIMILARITY TRANSFORM COMPUTATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Compute similarity transform to align source landmarks to target landmarks.
 * 
 * Uses stable landmarks (eyes, nose, mouth) to compute:
 * - Scale factor
 * - Rotation angle
 * - Translation offset
 * 
 * This ensures facial proportions are preserved when warping.
 */
export function computeSimilarityTransform(
    sourceLandmarks: FaceLandmarks,
    targetLandmarks: FaceLandmarks
): SimilarityTransform {
    // Use inter-ocular distance for scale
    const sourceIOD = getInterocularDistance(sourceLandmarks)
    const targetIOD = getInterocularDistance(targetLandmarks)
    const scale = targetIOD / sourceIOD

    // Use eye angle for rotation
    const sourceRotation = getFaceRotation(sourceLandmarks)
    const targetRotation = getFaceRotation(targetLandmarks)
    const rotation = targetRotation - sourceRotation

    // Use eye center for translation (after scale and rotation)
    const sourceCenter = getEyeCenter(sourceLandmarks)
    const targetCenter = getEyeCenter(targetLandmarks)

    // Apply scale and rotation to source center
    const cos = Math.cos(rotation)
    const sin = Math.sin(rotation)
    const scaledX = sourceCenter.x * scale
    const scaledY = sourceCenter.y * scale
    const rotatedX = scaledX * cos - scaledY * sin
    const rotatedY = scaledX * sin + scaledY * cos

    // Translation to align centers
    const translateX = targetCenter.x - rotatedX
    const translateY = targetCenter.y - rotatedY

    console.log(`   ğŸ“ Transform: scale=${scale.toFixed(3)}, rotation=${(rotation * 180 / Math.PI).toFixed(2)}Â°`)
    console.log(`      translate=(${translateX.toFixed(1)}, ${translateY.toFixed(1)})`)

    return { scale, rotation, translateX, translateY }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FACE PIXEL WARPING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Warp face pixels using similarity transform.
 * 
 * This uses Sharp's affine transform to apply scale, rotation, and translation
 * to the original face pixels so they match the generated face geometry.
 */
export async function warpFacePixels(
    originalFaceBuffer: Buffer,
    originalBox: BoundingBox,
    targetBox: BoundingBox,
    transform: SimilarityTransform,
    targetWidth: number,
    targetHeight: number
): Promise<Buffer> {
    try {
        // Get original face dimensions
        const metadata = await sharp(originalFaceBuffer).metadata()
        if (!metadata.width || !metadata.height) {
            throw new Error('Cannot get face dimensions')
        }

        // Calculate new dimensions after scale
        const newWidth = Math.round(metadata.width * transform.scale)
        const newHeight = Math.round(metadata.height * transform.scale)

        // First, resize the face
        let warpedBuffer = await sharp(originalFaceBuffer)
            .resize(newWidth, newHeight, {
                kernel: sharp.kernel.lanczos3,
                fit: 'fill'
            })
            .toBuffer()

        // Apply rotation if significant
        if (Math.abs(transform.rotation) > 0.01) {
            const rotateDegrees = transform.rotation * 180 / Math.PI
            warpedBuffer = await sharp(warpedBuffer)
                .rotate(rotateDegrees, {
                    background: { r: 0, g: 0, b: 0, alpha: 0 }
                })
                .toBuffer()
        }

        // Get final warped dimensions
        const warpedMeta = await sharp(warpedBuffer).metadata()
        const warpedWidth = warpedMeta.width || newWidth
        const warpedHeight = warpedMeta.height || newHeight

        // Create transparent canvas at target size
        const canvas = await sharp({
            create: {
                width: targetWidth,
                height: targetHeight,
                channels: 4,
                background: { r: 0, g: 0, b: 0, alpha: 0 }
            }
        }).png().toBuffer()

        // Calculate position for warped face
        // Target position based on target box center
        const targetCenterX = targetBox.x + targetBox.width / 2
        const targetCenterY = targetBox.y + targetBox.height / 2

        const placeX = Math.round(targetCenterX - warpedWidth / 2)
        const placeY = Math.round(targetCenterY - warpedHeight / 2)

        // Composite warped face onto canvas
        const result = await sharp(canvas)
            .composite([{
                input: warpedBuffer,
                left: Math.max(0, placeX),
                top: Math.max(0, placeY),
                blend: 'over'
            }])
            .png()
            .toBuffer()

        console.log(`   âœ… Face warped: ${metadata.width}x${metadata.height} â†’ ${warpedWidth}x${warpedHeight}`)

        return result
    } catch (error) {
        console.error('âŒ Face warp failed:', error)
        throw error
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// UNIFIED WARP ALIGNMENT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Perform landmark-based warp alignment on face pixels.
 * 
 * This is called BEFORE face compositing to ensure:
 * - Nose size matches original
 * - Eye spacing matches original
 * - Mouth width matches original
 * - Face doesn't appear "zoomed"
 */
export async function alignFaceWithLandmarks(
    originalFaceBuffer: Buffer,
    originalFaceBox: BoundingBox,
    generatedFaceBox: BoundingBox,
    generatedImageWidth: number,
    generatedImageHeight: number
): Promise<WarpAlignmentResult> {
    console.log('\nğŸ“ LANDMARK-BASED WARP ALIGNMENT')
    console.log('   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')

    try {
        // Step 1: Estimate landmarks for both faces
        const originalLandmarks = estimateLandmarksFromBox(originalFaceBox)
        const generatedLandmarks = estimateLandmarksFromBox(generatedFaceBox)

        console.log(`   Original IOD: ${getInterocularDistance(originalLandmarks).toFixed(1)}px`)
        console.log(`   Generated IOD: ${getInterocularDistance(generatedLandmarks).toFixed(1)}px`)

        // Step 2: Compute similarity transform
        const transform = computeSimilarityTransform(originalLandmarks, generatedLandmarks)

        // Step 3: Warp original face pixels
        const warpedFaceBuffer = await warpFacePixels(
            originalFaceBuffer,
            originalFaceBox,
            generatedFaceBox,
            transform,
            generatedImageWidth,
            generatedImageHeight
        )

        console.log('   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
        console.log('   âœ… Face aligned to generated geometry')
        console.log('   ğŸ”’ Proportions preserved (nose, eyes, mouth)')

        return {
            success: true,
            warpedFaceBuffer,
            transform
        }
    } catch (error) {
        console.error('âŒ Warp alignment failed:', error)
        return {
            success: false,
            warpedFaceBuffer: originalFaceBuffer,
            transform: { scale: 1, rotation: 0, translateX: 0, translateY: 0 },
            error: error instanceof Error ? error.message : 'Unknown error'
        }
    }
}

/**
 * Extract face region from image for alignment.
 */
export async function extractFaceForAlignment(
    imageBuffer: Buffer,
    faceBox: BoundingBox
): Promise<Buffer> {
    return sharp(imageBuffer)
        .extract({
            left: Math.max(0, faceBox.x),
            top: Math.max(0, faceBox.y),
            width: faceBox.width,
            height: faceBox.height
        })
        .ensureAlpha()
        .png()
        .toBuffer()
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// LOGGING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export function logWarpAlignmentStatus(): void {
    console.log('\nğŸ“ WARP ALIGNMENT STATUS')
    console.log('   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    console.log('   Method: Landmark-based similarity transform')
    console.log('   Landmarks: eyes, nose tip, mouth corners')
    console.log('   Transform: scale + rotation + translation')
    console.log('   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    console.log('   Preserves: nose size, eye spacing, mouth width')
    console.log('   Prevents: "zoomed" or stretched appearance')
}
