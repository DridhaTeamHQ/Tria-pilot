import { renderTryOnFast } from './renderer'
import {
  cropIdentityRegion,
  extractIdentitySimple
} from './identity-cropper'
import {
  getOrCacheIdentity,
  getCacheStats
} from './identity-cache'
import {
  preprocessGarmentImage,
  logPreprocessStatus,
  type PreprocessResult
} from './garment-preprocessor'
import {
  buildGarmentEnforcementBlock,
  type StrictGarmentProfile
} from './garment-strict-schema'
// Intelligent Scene Analyzer - Prevents Hallucination
import {
  analyzeScene,
  logSceneAnalysis,
  type SceneAnalysisResult
} from './intelligent-scene-analyzer'
// Body-Aware Face Analyzer
import {
  analyzeUserFace,
  logFaceAnalysis,
  type FaceAnalysisResult
} from './gpt-face-analyzer'
// Ultra Fidelity Constraints
import {
  getUltraFidelityPrompt,
  logUltraFidelityStatus
} from './ultra-fidelity'
// Advanced AI Prompting (Research-Based)
import {
  ANTI_AI_TELL_TRIGGERS,
  IDENTITY_MARKERS,
  getPhotographicStyle,
  logAdvancedPrompting
} from './advanced-prompting'
// Image Complexity Analyzer
import {
  analyzeImageComplexity,
  generateComplexityPromptModifier,
  createComplexityAlertResponse,
  logComplexityAnalysis,
  type ComplexityAnalysisResult
} from './complexity-analyzer'
// Hyper-Realistic Generation Constraints
import {
  getHyperRealisticPrompt,
  logHyperRealisticStatus
} from './hyper-realistic'
// Face & Clothing Consistency Lock
import {
  getConsistencyLockPrompt,
  logConsistencyStatus
} from './consistency-lock'
// Background Preservation & Physics Realism
import {
  getBackgroundPhysicsPrompt,
  logBackgroundPhysicsStatus
} from './background-physics'
// Anti-AI Look Controls
import {
  getAntiAILookPrompt,
  logAntiAIStatus
} from './anti-ai-look'

export interface TryOnQualityOptions {
  quality: 'fast' | 'high'
  aspectRatio?: string
  resolution?: string
}

export interface TryOnPresetInput {
  id?: string  // Preset ID for Higgsfield-style scene lookup in renderer
  pose_name?: string
  lighting_name?: string
  background_name?: string
  style_pack?: string
  background_focus?: string
  identity_lock?: 'normal' | 'high'
}

export interface TryOnPipelineResult {
  image: string
  debug: {
    shootPlanText: string
    usedGarmentExtraction: boolean
    timeMs: number
    preset?: string
    identityImagesUsed?: number
    identityCached?: boolean
    identityHash?: string
  }
}

const IDENTITY_SAFE_FORBIDDEN_TERMS = [
  'jawline',
  'cheeks',
  'face shape',
  'expression',
  'handsome',
  'sharp',
  'perfect',
  'symmetry'
]

const IDENTITY_SAFE_FACIAL_DESCRIPTOR_PATTERN =
  /\b(face|facial|jaw|jawline|cheek|cheeks|chin|nose|lips?|eyes?|eyebrow|forehead|temple|expression)\b/gi

function sanitizeIdentitySafePrompt(input?: string): string {
  let cleaned = input || ''
  for (const term of IDENTITY_SAFE_FORBIDDEN_TERMS) {
    const escaped = term.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
    cleaned = cleaned.replace(new RegExp(`\\b${escaped}\\b`, 'gi'), '')
  }
  cleaned = cleaned.replace(IDENTITY_SAFE_FACIAL_DESCRIPTOR_PATTERN, '')
  return cleaned.replace(/\s+/g, ' ').trim()
}

function assertIdentitySafePrompt(prompt: string): void {
  for (const term of IDENTITY_SAFE_FORBIDDEN_TERMS) {
    const escaped = term.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
    if (new RegExp(`\\b${escaped}\\b`, 'i').test(prompt)) {
      throw new Error(`IDENTITY_SAFE_PROMPT_BLOCKED: forbidden term "${term}"`)
    }
  }
  if (IDENTITY_SAFE_FACIAL_DESCRIPTOR_PATTERN.test(prompt)) {
    throw new Error('IDENTITY_SAFE_PROMPT_BLOCKED: facial descriptor detected')
  }
}

/**
 * FAST TRY-ON PIPELINE (PHASE 4 ARCHITECTURE)
 * 
 * IDENTITY PRESERVATION SYSTEM:
 * - Identity cropping: crop to upper body (head â†’ mid-torso)
 * - Session cache: reuse identity across generations
 * - HEAD_SCALE_LOCK, CAMERA_CONSTRAINT, POSE_INHERITANCE active
 * 
 * Single API call to Gemini with:
 * - Image 1: Person (cropped identity, cached)
 * - Image 2: Garment (visual reference only)
 */
export async function runTryOnPipelineV3(params: {
  subjectImageBase64: string
  clothingRefBase64: string
  preset?: TryOnPresetInput
  userRequest?: string
  quality: TryOnQualityOptions
  /** Enable identity cropping (recommended for 90%+ consistency) */
  useIdentityCropping?: boolean
  /** User ID for session cache (enables character memory) */
  userId?: string
  /** Skip garment preprocessing (escape hatch, not recommended) */
  skipGarmentPreprocessing?: boolean
  /** Final render guard: Flash must never be used for final influencer output. */
  finalRender?: boolean
  /** Influencer identity-safe mode: disable face analysis and facial prompt authority. */
  identitySafe?: boolean
}): Promise<TryOnPipelineResult> {
  const startTime = Date.now()

  const {
    subjectImageBase64,
    clothingRefBase64,
    preset,
    userRequest,
    quality,
    useIdentityCropping = true,  // Default ON for identity preservation
    userId = 'anonymous',
    skipGarmentPreprocessing = false,  // Default: preprocessing enabled
    finalRender = false,
    identitySafe = false
  } = params

  if (identitySafe) {
    console.log('INFLUENCER TRY-ON IDENTITY SAFE MODE: ACTIVE')
  }

  // HARD STOP: Flash pipeline must never be used for final render
  // FLASH MUST NEVER RENDER FINAL IMAGE
  if (finalRender) {
    throw new Error('FINAL_RENDER_FORBIDDEN: flash pipeline cannot be used for final render')
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // GARMENT PREPROCESSING LAYER (NEW)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  let processedClothingImage = clothingRefBase64
  let garmentPreprocessResult: PreprocessResult | null = null

  if (!skipGarmentPreprocessing) {
    console.log(`\nğŸ‘” GARMENT PREPROCESSING: Starting...`)

    garmentPreprocessResult = await preprocessGarmentImage(clothingRefBase64, {
      sessionId: `pipeline-${startTime}`,
      model: quality.quality === 'high' ? 'pro' : 'flash'
    })

    processedClothingImage = garmentPreprocessResult.processedImage
    logPreprocessStatus(`pipeline-${startTime}`, garmentPreprocessResult)
  } else {
    console.log(`\nâ­ï¸ GARMENT PREPROCESSING: Skipped (flag set)`)
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // STRICT GARMENT ENFORCEMENT BLOCK (for pattern/color accuracy)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  let garmentEnforcementBlock: string | undefined
  if (garmentPreprocessResult?.strictGarmentProfile) {
    garmentEnforcementBlock = buildGarmentEnforcementBlock(garmentPreprocessResult.strictGarmentProfile)
    console.log(`ğŸ‘” STRICT GARMENT ENFORCEMENT: Generated (pattern: ${garmentPreprocessResult.strictGarmentProfile.pattern?.exists ? garmentPreprocessResult.strictGarmentProfile.pattern.type : 'solid'})`)
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // IDENTITY CROPPING & CACHING
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  let processedIdentityImage = subjectImageBase64
  let identityHash: string | undefined
  let identityCached = false

  if (identitySafe) {
    // IDENTITY-SAFE MODE: DISABLED TO PREVENT FACE DRIFT
    console.log('IDENTITY-SAFE MODE: using original person image only (no identity cropping)')
  } else if (useIdentityCropping) {
    try {
      // Try full cropping with Sharp
      const cropped = await cropIdentityRegion(subjectImageBase64)

      // Cache by (userId + identityHash)
      const cached = getOrCacheIdentity(userId, cropped)

      processedIdentityImage = cached.croppedImageBase64
      identityHash = cached.identityHash
      identityCached = cached.useCount > 1

      console.log(`ğŸ”’ IDENTITY SYSTEM:`)
      console.log(`   Cropping: âœ“ (upper body)`)
      console.log(`   Hash: ${identityHash}`)
      console.log(`   Cached: ${identityCached ? 'âœ“ (reused)' : 'âœ— (new)'}`)
      console.log(`   Use count: ${cached.useCount}`)
    } catch (e) {
      // Fallback to simple extraction (just hash, no crop)
      console.warn('âš ï¸ Identity cropping failed, using fallback')
      const simple = extractIdentitySimple(subjectImageBase64)
      identityHash = simple.identityHash
      processedIdentityImage = subjectImageBase64
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // INTELLIGENT SCENE ANALYSIS (PREVENTS HALLUCINATION)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  let sceneAnalysis: SceneAnalysisResult | null = null
  let faceAnalysis: FaceAnalysisResult | null = null
  let complexityAnalysis: ComplexityAnalysisResult | null = null

  if (identitySafe) {
    // IDENTITY-SAFE MODE: DISABLED TO PREVENT FACE DRIFT
    console.log('IDENTITY-SAFE MODE: skipped scene/face/complexity analysis')
  } else {
    try {
      console.log(`\nğŸ¬ INTELLIGENT SCENE ANALYSIS: Starting...`)

      // Analyze the ENTIRE input image to understand context
      sceneAnalysis = await analyzeScene(
        subjectImageBase64,
        `pipeline-${startTime}`
      )
      logSceneAnalysis(sceneAnalysis, `pipeline-${startTime}`)

      // Also do body-aware face analysis
      faceAnalysis = await analyzeUserFace(
        subjectImageBase64,
        `pipeline-${startTime}`
      )
      logFaceAnalysis(faceAnalysis, `pipeline-${startTime}`)

      // Analyze image complexity for alerts
      complexityAnalysis = await analyzeImageComplexity(
        subjectImageBase64,
        `pipeline-${startTime}`
      )
      logComplexityAnalysis(complexityAnalysis, `pipeline-${startTime}`)

      console.log(`   âœ… Scene + Face + Complexity analysis complete`)
    } catch (analysisError) {
      console.warn(`   âš ï¸ Analysis failed, using fallback:`, analysisError)
    }
  }

  // Extract preset values - ID is critical for scene lookup in renderer
  const presetId = preset?.id
  const backgroundName = preset?.background_name || 'keep the original background'
  const lightingName = preset?.lighting_name || 'natural lighting'

  // Build scene instruction - SIMPLIFIED to reduce token count
  // Previous version was causing 32K token overflow
  let sceneInstruction = backgroundName

  // NOTE: Removed all the verbose prompts (ultraFidelity, hyperRealistic, etc.)
  // that were causing token limit exceeded. Less is more for model focus.

  console.log(`\nğŸ¯ SIMPLIFIED SCENE INSTRUCTION: ${sceneInstruction.slice(0, 100)}...`)

  console.log(`\n========== TRY-ON PIPELINE (PHASE 5 - GARMENT EXTRACTION) ==========`)
  console.log(`ğŸ¨ Preset ID: ${presetId || 'none'}`)
  console.log(`ğŸ“¸ Background: "${backgroundName}"`)
  console.log(`ğŸ’¡ Lighting: "${lightingName}"`)
  console.log(`ğŸ¯ Quality: ${quality.quality}`)
  console.log(`ğŸ”’ HEAD_SCALE_LOCK: âœ“`)
  console.log(`ğŸ“· CAMERA_CONSTRAINT: âœ“`)
  console.log(`ğŸ§ POSE_INHERITANCE: âœ“`)
  console.log(`ğŸ‘” GARMENT_EXTRACTION: ${garmentPreprocessResult?.wasExtracted ? 'âœ“ (extracted)' : 'âœ— (passthrough)'}`)
  console.log(`ğŸ“Š Cache stats: ${JSON.stringify(getCacheStats())}`)
  console.log(`=====================================\n`)

  const safeUserRequest = identitySafe
    ? sanitizeIdentitySafePrompt(userRequest)
    : userRequest
  if (identitySafe && safeUserRequest) {
    assertIdentitySafePrompt(safeUserRequest)
  }

  // Single render call - PHASE 5: Cropped identity + Preprocessed Garment
  const image = await renderTryOnFast({
    subjectImageBase64: processedIdentityImage, // Image 1: Cropped identity
    garmentImageBase64: processedClothingImage, // Image 2: Garment (preprocessed, body-free)
    backgroundInstruction: sceneInstruction,
    lightingInstruction: lightingName,
    quality: quality.quality,
    aspectRatio: quality.aspectRatio,
    resolution: quality.resolution,
    stylePresetId: presetId,
    userRequest: safeUserRequest, // Pass sanitized request in identity-safe mode
    garmentEnforcementBlock, // Strict pattern/color enforcement
  })

  const elapsed = Date.now() - startTime
  console.log(`âœ… Pipeline completed in ${(elapsed / 1000).toFixed(1)}s`)

  return {
    image,
    debug: {
      shootPlanText: sceneInstruction,
      usedGarmentExtraction: garmentPreprocessResult?.wasExtracted || false,
      timeMs: elapsed,
      preset: presetId,
      identityImagesUsed: 1,
      identityCached,
      identityHash,
    },
  }
}

